{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hISyWd5xWEmR",
        "outputId": "53396197-86e9-4cca-a81e-893e712bdc72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of uniprot human verified proteins: 20434\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "data_file_path = \"../PCFs/files_for_ml/protein_props/protein_props.json\"\n",
        "\n",
        "with open(data_file_path, 'r') as f:\n",
        "    protein_data = json.load(f)\n",
        "\n",
        "print(\"Total number of uniprot human verified proteins:\", len(protein_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykkHuSqOWE4n",
        "outputId": "ade1fe56-294b-4c81-fc23-a9cf7222ffe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Sequence Length: 34350\n",
            "Minimum Sequence Length: 2\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = -1\n",
        "min_seq_length = 1e10\n",
        "\n",
        "for protein in protein_data:\n",
        "  seq_length = len(protein_data[protein]['Sequence'])\n",
        "  max_seq_length = max(max_seq_length, seq_length)\n",
        "  min_seq_length = min(min_seq_length, seq_length)\n",
        "\n",
        "print(\"Maximum Sequence Length:\", max_seq_length)\n",
        "print(\"Minimum Sequence Length:\", min_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue5pHLHGWYBn",
        "outputId": "186e540a-185e-4a60-93c7-e0c635e8ffcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Unique Amino Acids: 20\n"
          ]
        }
      ],
      "source": [
        "unique_amino_acids = set()\n",
        "\n",
        "for protein in protein_data:\n",
        "  seq = protein_data[protein]['Sequence']\n",
        "  for aa in seq:\n",
        "    unique_amino_acids.add(aa)\n",
        "\n",
        "print(\"Number of Unique Amino Acids:\", len(unique_amino_acids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWNUdttrcGc0",
        "outputId": "431fcc51-f550-4913-af08-84c58acdac67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'A': 0,\n",
              " 'C': 1,\n",
              " 'D': 2,\n",
              " 'E': 3,\n",
              " 'F': 4,\n",
              " 'G': 5,\n",
              " 'H': 6,\n",
              " 'I': 7,\n",
              " 'K': 8,\n",
              " 'L': 9,\n",
              " 'M': 10,\n",
              " 'N': 11,\n",
              " 'P': 12,\n",
              " 'Q': 13,\n",
              " 'R': 14,\n",
              " 'S': 15,\n",
              " 'T': 16,\n",
              " 'V': 17,\n",
              " 'W': 18,\n",
              " 'Y': 19}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "amino_acid_to_num_aa = {aa: i for i, aa in enumerate(sorted(unique_amino_acids))}\n",
        "amino_acid_to_num_aa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SwdnCHUTcjhE"
      },
      "outputs": [],
      "source": [
        "MAX_SEQ_LENGTH = 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4jBaQn2scLGn"
      },
      "outputs": [],
      "source": [
        "sequence_encoding = {}\n",
        "\n",
        "for protein in protein_data:\n",
        "  seq = protein_data[protein]['Sequence']\n",
        "  if len(seq) <= MAX_SEQ_LENGTH:\n",
        "    encoded_seq = [amino_acid_to_num_aa[aa] for aa in seq]\n",
        "    sequence_encoding[protein] = encoded_seq\n",
        "    while(len(sequence_encoding[protein]) <= MAX_SEQ_LENGTH):\n",
        "      sequence_encoding[protein].extend(encoded_seq)\n",
        "    sequence_encoding[protein] = sequence_encoding[protein][:MAX_SEQ_LENGTH]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6fO-eZ8VdOXp"
      },
      "outputs": [],
      "source": [
        "# Build a neural reconstruction network, where the input is the protein sequence of MAX_SEQ_LENGTH\n",
        "# and output is also same, latent layer is dimension 20\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataloader class\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    protein = list(self.data.keys())[idx]\n",
        "    seq = self.data[protein]\n",
        "    return torch.tensor(seq), torch.tensor(seq)\n",
        "\n",
        "# Reconstruction Network\n",
        "class ReconstructionNetwork(nn.Module):\n",
        "  def __init__(self, latent_layer_dim):\n",
        "    super(ReconstructionNetwork, self).__init__()\n",
        "    self.latent_layer_dim = latent_layer_dim\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(MAX_SEQ_LENGTH, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, latent_layer_dim)\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(latent_layer_dim, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, MAX_SEQ_LENGTH)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    latent = self.encoder(x)\n",
        "    reconstructed = self.decoder(latent)\n",
        "    return latent, reconstructed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T5maKkK0eZok"
      },
      "outputs": [],
      "source": [
        "def train_network(model, train_loader, optimizer, criterion, num_epochs):\n",
        "  train_losses = []\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for seq, _ in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      _, reconstructed = model(seq.float())\n",
        "      loss = criterion(reconstructed, seq.float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader)}\")\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "\n",
        "  return train_losses, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CGKn16Yewx9",
        "outputId": "89127bc4-aaa1-4b57-d7e7-c213f59a7fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 48.13909739982791\n",
            "Epoch 3/10, Train Loss: 30.32687052284799\n",
            "Epoch 4/10, Train Loss: 30.32943972145639\n",
            "Epoch 5/10, Train Loss: 30.33499299026117\n",
            "Epoch 6/10, Train Loss: 30.3258369259718\n",
            "Epoch 7/10, Train Loss: 30.34180194575612\n",
            "Epoch 8/10, Train Loss: 30.324753970634646\n",
            "Epoch 9/10, Train Loss: 30.323198411522842\n",
            "Epoch 10/10, Train Loss: 30.33403377998166\n"
          ]
        }
      ],
      "source": [
        "trainloader = DataLoader(MyDataset(sequence_encoding), batch_size=500, shuffle=True)\n",
        "model = ReconstructionNetwork(20)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "num_epochs = 10\n",
        "\n",
        "trainlosses, model = train_network(model, trainloader, optimizer, criterion, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oXmByuUye9k_"
      },
      "outputs": [],
      "source": [
        "# COllect latent values\n",
        "for protein in sequence_encoding:\n",
        "  latent, _ = model(torch.tensor(sequence_encoding[protein]).float())\n",
        "  sequence_encoding[protein] = latent.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hrgDr8Mvm1SC"
      },
      "outputs": [],
      "source": [
        "for protein in sequence_encoding:\n",
        "  encoding = sequence_encoding[protein]\n",
        "  encoding = {f\"encoding_{i}\":encoding[i] for i in range(len(encoding))}\n",
        "  sequence_encoding[protein] = encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwBo1alnmdw1",
        "outputId": "7812422d-ef35-4030-d818-d28e59e561fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'encoding_0': -17.60629,\n",
              " 'encoding_1': -41.13669,\n",
              " 'encoding_2': 42.415375,\n",
              " 'encoding_3': -10.006809,\n",
              " 'encoding_4': 44.50327,\n",
              " 'encoding_5': 9.062079,\n",
              " 'encoding_6': -11.936504,\n",
              " 'encoding_7': -20.683659,\n",
              " 'encoding_8': 3.984549,\n",
              " 'encoding_9': 37.785206,\n",
              " 'encoding_10': 12.472336,\n",
              " 'encoding_11': -55.68788,\n",
              " 'encoding_12': -19.370184,\n",
              " 'encoding_13': -11.168778,\n",
              " 'encoding_14': -13.122353,\n",
              " 'encoding_15': 10.536164,\n",
              " 'encoding_16': -36.11607,\n",
              " 'encoding_17': -63.010822,\n",
              " 'encoding_18': 20.33886,\n",
              " 'encoding_19': -19.18953}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_encoding[\"P05067\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BNW7XTDAmjMT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# save as csv\n",
        "df = pd.DataFrame.from_dict(sequence_encoding)\n",
        "df.to_csv(\"files_for_ml/latent_values.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-hV4EK5mz7-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
