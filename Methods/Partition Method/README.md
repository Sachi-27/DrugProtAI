# ðŸ§  Partition Method & Ablation Studies

This folder contains code and results related to our custom **Partition Ensemble Classifier (PEC)** approach for druggability prediction using various machine learning algorithms and feature sets. The implementation and experiments are primarily documented in the notebook:

> ðŸ““ `partition_method_ablation_study.ipynb`

---

## âš™ï¸ Model Selection Ablation Study

We evaluate different machine learning algorithms under a consistent PEC setup. You can specify the model under test via the `MODEL_UNDER_TEST` variable, with the following options:

- `"xgb"` â€“ XGBoost Classifier
- `"rf"` â€“ Random Forest Classifier
- `"lr"` â€“ Logistic Regression
- `"svm_linear"` â€“ Support Vector Machine (Linear Kernel)
- `"svm_rbf"` â€“ Support Vector Machine (RBF Kernel)
- `"knn"` â€“ K-Nearest Neighbors
- `"nb"` â€“ Gaussian Naive Bayes

We maintain a consistent evaluation setup with a **held-out test set of 600 proteins** (300 druggable, 300 non-druggable).

### ðŸ“Š Summary of Performance Across Models

| Model                 | Total Accuracy | Druggable Accuracy (Sensitivity) | Non-Druggable Accuracy (Specificity) |
|----------------------|----------------|----------------------------------|--------------------------------------|
| **XGBoost**          | 78.06 Â± 2.03   | 78.73 Â± 2.82                     | 77.38 Â± 2.43                         |
| **Random Forest**    | 75.94 Â± 1.55   | 77.73 Â± 1.95                     | 74.15 Â± 2.36                         |
| Logistic Regression  | 63.34 Â± 2.07   | 65.53 Â± 3.27                     | 61.15 Â± 2.12                         |
| SVM (Linear Kernel)  | 50.19 Â± 0.74   | 91.53 Â± 20.75                    | 8.85 Â± 20.82                         |
| SVM (RBF Kernel)     | 49.74 Â± 0.65   | 94.28 Â± 12.78                    | 5.20 Â± 12.43                         |
| K-Nearest Neighbors  | 58.58 Â± 1.63   | 64.28 Â± 2.43                     | 52.87 Â± 2.78                         |
| Naive Bayes          | 57.30 Â± 1.78   | 25.50 Â± 4.34                     | 89.10 Â± 2.15                         |

> ðŸ” **Conclusion**: XGBoost and Random Forest consistently outperform other models across key metrics.

---

## ðŸ§¬ Feature Group Comparisons

We compare the effect of using different types of features, specified via `FEATURE_GROUP`:

- `"seq_only"` â€“ Sequence-derived features:
  - Physicochemical properties
  - GDPC encodings
  - Flexibility properties
  - Latent neural network-derived features
- `"non_seq_only"` â€“ Non-sequence features:
  - PTM and glycosylation counts
  - PPI-based features (pairwise & network)
  - Subcellular localization
  - Protein domain information
- `"all"` â€“ Combined feature set
- `"esm_instead_of_latent"` â€“ Combined feature set except that latent values replaced with ESM2 embeddings 

### ðŸ“Š Performance of XGBoost PEC on Different Feature Groups

| Feature Group                                      | Total Accuracy | Sensitivity  | Specificity  |
| -------------------------------------------------- | -------------- | ------------ | ------------ |
| All Features                                       | 78.06 Â± 2.03   | 78.73 Â± 2.82 | 77.38 Â± 2.43 |
| Seq-only                                           | 71.71 Â± 1.47   | 74.25 Â± 2.15 | 69.17 Â± 2.50 |
| Non-seq only                                       | 75.14 Â± 1.38   | 76.15 Â± 2.57 | 74.13 Â± 1.75 |
| All Features but ESM2 embeddings instead of Latent | 82.78 Â± 1.55   | 83.95 Â± 1.98 | 81.60 Â± 2.47 |

### ðŸ“Š Performance of Random Forest PEC on Different Feature Groups

| Feature Group                                      | Total Accuracy | Sensitivity  | Specificity  |
| -------------------------------------------------- | -------------- | ------------ | ------------ |
| All Features                                       | 75.94 Â± 1.55   | 77.73 Â± 1.95 | 74.15 Â± 2.36 |
| Seq-only                                           | 70.43 Â± 2.19   | 71.73 Â± 2.76 | 69.13 Â± 2.95 |
| Non-seq only                                       | 74.33 Â± 1.60   | 77.65 Â± 2.80 | 71.02 Â± 2.13 |
| All Features but ESM2 embeddings instead of Latent | 77.80 Â± 1.89   | 79.30 Â± 2.36 | 76.30 Â± 2.63 |

> âœ… **Observation**: Non-sequence features significantly contribute to predictive performance and should not be excluded.

---

## ðŸ§¬ Partition Method on ESM2 Embeddings

We also extend the PEC framework to test ESM2 protein embeddings using XGBoost, under different preprocessing choices:

- `none`: Raw ESM2 embeddings (no scaling)
- `standard`: StandardScaler normalization
- `minmax`: MinMaxScaler normalization

### ðŸ“Š XGBoost PEC on ESM2 Embeddings

| Preprocessing      | Total Accuracy | Sensitivity | Specificity |
|--------------------|----------------|-------------|-------------|
| No preprocessing   | 80.99 Â± 1.95   | 82.37 Â± 2.61 | 79.62 Â± 2.36 |
| Standard Scaling   | 81.47 Â± 1.42   | 82.78 Â± 2.03 | 80.15 Â± 1.64 |
| MinMax Scaling     | 81.27 Â± 1.60   | 82.62 Â± 2.24 | 79.92 Â± 2.52 |

> ðŸ“ˆ **Insight**: Scaling has a marginal positive effect on XGBoost performance when using high-dimensional ESM2 embeddings.

---


